{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation System BIGDATA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6tJ32O4dMedy/fJyZtueJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinhhungGM/RecommendationSystemUsingBigData/blob/main/Recommendation_System_BIGDATA_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzbuD1MZ98qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42054a3-d62b-4313-bedc-8bafa9c7b70e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3USkU_eE-O_A"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0eMXglQ-rJG"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po9ZZt5Y-uxb"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuWWE8Tt-_1U"
      },
      "source": [
        "!pip install -q findspark py4j\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzkcq6QammiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746b5dfa-b04d-41d7-8da5-84b97356bac7"
      },
      "source": [
        "!pip install pandas --upgrade"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvneHzZxpi_-"
      },
      "source": [
        "# Approach with Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22wTuJKUCyYG"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLueItI_C7RT"
      },
      "source": [
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark import SparkContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext\n",
        "# sc.setCheckpointDir('checkpoint')\n",
        "spark = SparkSession.builder.appName('Group 7 - Recommendation System').config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
        ".config('spark.driver.memory','8G') \\\n",
        ".config('spark.ui.showConsoleProgress', True) \\\n",
        ".config('spark.sql.repl.eagerEval.enabled', True) \\\n",
        ".config('spark.sql.pivotMaxValues', 100000000)\\\n",
        ".getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D1AzOMfD8j_"
      },
      "source": [
        "# Data is downloaded from https://www.kaggle.com/bandikarthik/movie-recommendation-system\n",
        "movies = spark.read.csv('drive/MyDrive/BigDataProject/movies.csv', header=True, inferSchema=True)\n",
        "ratings = spark.read.csv('drive/MyDrive/BigDataProject/ratings.csv',  header=True, inferSchema=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHdgQLPhEZTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be23e6f-c77e-42c9-e977-529c4dee7ec5"
      },
      "source": [
        "movies.limit(5).show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6vjhOoWFCD3"
      },
      "source": [
        "# Calculating sparsity of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZrXM-UlEyJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356ec295-59e9-49ae-db42-ad385b664ee2"
      },
      "source": [
        "numerator = ratings.select(\"Rating\").count()\n",
        "\n",
        "# Count the number of distinct userIds and distinct movieIds\n",
        "unique_users = ratings.select(\"UserID\").distinct().count()\n",
        "unique_movies = ratings.select(\"MovieID\").distinct().count()\n",
        "\n",
        "# Set the denominator equal to the number of users multiplied by the number of movies\n",
        "denominator = unique_users * unique_movies\n",
        "\n",
        "# Divide the numerator by the denominator\n",
        "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
        "print(\"The ratings data is \", \"%.2f\" % sparsity + \"% empty.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The ratings data is  99.73% empty.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzz1Wa3dGRgF"
      },
      "source": [
        "# Implementing ALS(Alternating Least Square) algorithm in Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VpWg2z2FYly"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq2s6QbVGAAY"
      },
      "source": [
        "(trainData, testData) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
        "\n",
        "# Create ALS model\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False\n",
        "          , coldStartStrategy=\"drop\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2kz5AEJG7IE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e0187b-1570-4db0-c648-6b0c5ce22d7d"
      },
      "source": [
        "%%time\n",
        "param_grid = ParamGridBuilder() \\\n",
        ".addGrid(als.rank, [14]) \\\n",
        ".addGrid(als.maxIter, [5]) \\\n",
        ".addGrid(als.regParam, [.01]) \\\n",
        ".build()\n",
        "\n",
        "\n",
        "# rank is the number of latent factors in the model (defaults to 10).\n",
        "# maxIter is the maximum number of iterations to run (defaults to 10).\n",
        "# regParam specifies the regularization parameter in ALS (defaults to 1.0).\n",
        "\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
        "cv = CrossValidator(estimator=als,\n",
        "                            estimatorParamMaps=param_grid,\n",
        "                            evaluator=evaluator,\n",
        "                            numFolds=3) \n",
        "\n",
        "model = cv.fit(trainData)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.6 s, sys: 584 ms, total: 5.19 s\n",
            "Wall time: 13min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UVdWQHPHP3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129ea49d-7924-4341-a13a-03a0d9b7a060"
      },
      "source": [
        "best_model = model.bestModel\n",
        "predictions = best_model.transform(testData)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root mean square error: {rmse}\")\n",
        "print(\"====BEST MODEL ====\")\n",
        "print(f\"BEST RANK: {best_model.rank}\")\n",
        "print(f\"maxIter: {best_model._java_obj.parent().getMaxIter()}\")\n",
        "print(f\"regParam: {best_model._java_obj.parent().getRegParam()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root mean square error: 0.8435874393514843\n",
            "====BEST MODEL ====\n",
            "BEST RANK: 14\n",
            "maxIter: 5\n",
            "regParam: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "3zIcqurUf567",
        "outputId": "b9da3979-6a7c-4af1-8e22-093b89f85cc6"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>userId</th><th>movieId</th><th>rating</th><th>timestamp</th><th>prediction</th></tr>\n",
              "<tr><td>137389</td><td>148</td><td>3.0</td><td>830778220</td><td>1.9708189</td></tr>\n",
              "<tr><td>90446</td><td>148</td><td>2.0</td><td>941903738</td><td>2.901287</td></tr>\n",
              "<tr><td>77231</td><td>148</td><td>2.0</td><td>1030400425</td><td>1.8130058</td></tr>\n",
              "<tr><td>224425</td><td>148</td><td>3.0</td><td>837811440</td><td>2.939558</td></tr>\n",
              "<tr><td>236731</td><td>148</td><td>3.0</td><td>843889974</td><td>3.0693476</td></tr>\n",
              "<tr><td>246361</td><td>148</td><td>3.0</td><td>834673760</td><td>2.570979</td></tr>\n",
              "<tr><td>136989</td><td>148</td><td>1.0</td><td>833673768</td><td>3.275115</td></tr>\n",
              "<tr><td>135040</td><td>148</td><td>5.0</td><td>958498293</td><td>4.768713</td></tr>\n",
              "<tr><td>187508</td><td>148</td><td>2.0</td><td>874577512</td><td>3.3299313</td></tr>\n",
              "<tr><td>204347</td><td>148</td><td>3.0</td><td>834040799</td><td>4.3313537</td></tr>\n",
              "<tr><td>243222</td><td>148</td><td>2.0</td><td>916754151</td><td>2.9960375</td></tr>\n",
              "<tr><td>66430</td><td>148</td><td>1.0</td><td>833133885</td><td>2.6211414</td></tr>\n",
              "<tr><td>33400</td><td>148</td><td>3.0</td><td>840444102</td><td>3.3747706</td></tr>\n",
              "<tr><td>229589</td><td>148</td><td>1.0</td><td>837770520</td><td>2.6647415</td></tr>\n",
              "<tr><td>101628</td><td>148</td><td>3.0</td><td>856710018</td><td>2.3062277</td></tr>\n",
              "<tr><td>184545</td><td>148</td><td>1.0</td><td>840355078</td><td>2.1200023</td></tr>\n",
              "<tr><td>62154</td><td>148</td><td>4.0</td><td>831240840</td><td>4.3012037</td></tr>\n",
              "<tr><td>180418</td><td>148</td><td>2.0</td><td>837251123</td><td>2.734067</td></tr>\n",
              "<tr><td>86384</td><td>148</td><td>3.0</td><td>1027645782</td><td>2.998755</td></tr>\n",
              "<tr><td>59280</td><td>148</td><td>3.0</td><td>836248537</td><td>3.4010844</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ],
            "text/plain": [
              "+------+-------+------+----------+----------+\n",
              "|userId|movieId|rating| timestamp|prediction|\n",
              "+------+-------+------+----------+----------+\n",
              "|137389|    148|   3.0| 830778220| 1.9708189|\n",
              "| 90446|    148|   2.0| 941903738|  2.901287|\n",
              "| 77231|    148|   2.0|1030400425| 1.8130058|\n",
              "|224425|    148|   3.0| 837811440|  2.939558|\n",
              "|236731|    148|   3.0| 843889974| 3.0693476|\n",
              "|246361|    148|   3.0| 834673760|  2.570979|\n",
              "|136989|    148|   1.0| 833673768|  3.275115|\n",
              "|135040|    148|   5.0| 958498293|  4.768713|\n",
              "|187508|    148|   2.0| 874577512| 3.3299313|\n",
              "|204347|    148|   3.0| 834040799| 4.3313537|\n",
              "|243222|    148|   2.0| 916754151| 2.9960375|\n",
              "| 66430|    148|   1.0| 833133885| 2.6211414|\n",
              "| 33400|    148|   3.0| 840444102| 3.3747706|\n",
              "|229589|    148|   1.0| 837770520| 2.6647415|\n",
              "|101628|    148|   3.0| 856710018| 2.3062277|\n",
              "|184545|    148|   1.0| 840355078| 2.1200023|\n",
              "| 62154|    148|   4.0| 831240840| 4.3012037|\n",
              "|180418|    148|   2.0| 837251123|  2.734067|\n",
              "| 86384|    148|   3.0|1027645782|  2.998755|\n",
              "| 59280|    148|   3.0| 836248537| 3.4010844|\n",
              "+------+-------+------+----------+----------+\n",
              "only showing top 20 rows"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D60NGNliHeGs"
      },
      "source": [
        "# Movie Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXmHNXDtHbl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95438d4-bc46-46e1-bf74-b4bfa84989a0"
      },
      "source": [
        "# Generate top 10 movie recommendations for each user\n",
        "# Recommend Film based on Users\n",
        "# Output will be movieId and rating\n",
        "recommendations = best_model.recommendForAllUsers(10)\n",
        "recommendations.limit(10).show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   148|[{144708, 23.4303...|\n",
            "|   463|[{144708, 22.5578...|\n",
            "|   471|[{107516, 24.2774...|\n",
            "|   496|[{107516, 23.2242...|\n",
            "|   833|[{144708, 24.6131...|\n",
            "|  1088|[{107516, 24.0861...|\n",
            "|  1238|[{107516, 17.8833...|\n",
            "|  1342|[{130576, 15.7069...|\n",
            "|  1580|[{144708, 21.0237...|\n",
            "|  1591|[{144708, 17.6400...|\n",
            "+------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4XY-d8CJYNx"
      },
      "source": [
        "### 7th User’s Actual Preference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTh0G83FJG3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d265eaf4-36aa-4c8f-842e-391d5cf9a922"
      },
      "source": [
        "ratings.join(movies, on='movieId').filter('userId = 7') \\\n",
        ".sort('rating', ascending=False).limit(10).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------+----------+--------------------+--------------------+\n",
            "|movieId|userId|rating| timestamp|               title|              genres|\n",
            "+-------+------+------+----------+--------------------+--------------------+\n",
            "| 134853|     7|   5.0|1451817861|   Inside Out (2015)|Animation|Childre...|\n",
            "|   4226|     7|   5.0|1451817880|      Memento (2000)|    Mystery|Thriller|\n",
            "|   5618|     7|   5.0|1451817882|Spirited Away (Se...|Adventure|Animati...|\n",
            "|  58559|     7|   5.0|1451817836|Dark Knight, The ...|Action|Crime|Dram...|\n",
            "|  79132|     7|   5.0|1451817881|    Inception (2010)|Action|Crime|Dram...|\n",
            "| 109487|     7|   5.0|1451817912| Interstellar (2014)|         Sci-Fi|IMAX|\n",
            "| 122886|     7|   5.0|1451817862|Star Wars: Episod...|Action|Adventure|...|\n",
            "| 134130|     7|   5.0|1451817860| Martian, The (2015)|Action|Adventure|...|\n",
            "|   3147|     7|   4.5|1451817855|Green Mile, The (...|         Crime|Drama|\n",
            "|   1196|     7|   4.0|1451817837|Star Wars: Episod...|Action|Adventure|...|\n",
            "+-------+------+------+----------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qmZQCsNJ3IN"
      },
      "source": [
        "### 7th User’s ALS Recommentions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvwJ3UA4J55o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd48af8f-9800-4b26-be2d-54edaa6e565b"
      },
      "source": [
        "recommendations = recommendations.withColumn(\"rec_exp\", explode(\"recommendations\")).select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
        "recommendations.join(movies, on='movieId').filter('userId = 7').show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-31466f4ad691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rec_exp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recommendations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rec_exp.movieId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rec_exp.rating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'userId = 7'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \"\"\"\n\u001b[1;32m   2454\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`recommendations`' given input columns: [movieId, rating, userId];\n'Project [userId#1626, movieId#2884, rating#2885, explode('recommendations) AS rec_exp#2977]\n+- Project [userId#1626, rec_exp#2880.movieId AS movieId#2884, rec_exp#2880.rating AS rating#2885]\n   +- Project [userId#1626, recommendations#1627, rec_exp#2880]\n      +- Generate explode(recommendations#1627), false, [rec_exp#2880]\n         +- Project [id#1622 AS userId#1626, cast(recommendations#1623 as array<struct<movieId:int,rating:float>>) AS recommendations#1627]\n            +- Project [key#1616 AS id#1622, TopByKeyAggregator(scala.Tuple3)#1621 AS recommendations#1623]\n               +- Aggregate [value#1608], [value#1608 AS key#1616, topbykeyaggregator(org.apache.spark.ml.recommendation.TopByKeyAggregator@3f23c41d, Some(newInstance(class scala.Tuple3)), Some(class scala.Tuple3), Some(StructType(StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false))), encodeusingserializer(input[0, java.lang.Object, true], true), decodeusingserializer(input[0, binary, true], org.apache.spark.util.BoundedPriorityQueue, true), mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 71), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 71))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 71))._1, _2, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 71))._2), input[0, [Lscala.Tuple2;, true], None), ArrayType(StructType(StructField(_1,IntegerType,false), StructField(_2,FloatType,false)),true), true, 0, 0) AS TopByKeyAggregator(scala.Tuple3)#1621]\n                  +- AppendColumns org.apache.spark.ml.recommendation.ALSModel$$Lambda$3640/102511255@7122561f, class scala.Tuple3, [StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false)], newInstance(class scala.Tuple3), [input[0, int, false] AS value#1608]\n                     +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._1 AS _1#1597, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._2 AS _2#1598, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._3 AS _3#1599]\n                        +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$3638/1465570088@2136ae1a, obj#1596: scala.Tuple3\n                           +- DeserializeToObject newInstance(class scala.Tuple2), obj#1595: scala.Tuple2\n                              +- Join Cross\n                                 :- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 50), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 50))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 50))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 50))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#1575]\n                                 :  +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3625/1299762647@57c0f08b, obj#1574: scala.collection.Seq\n                                 :     +- DeserializeToObject newInstance(class scala.Tuple2), obj#1573: scala.Tuple2\n                                 :        +- Project [_1#1486 AS id#1491, _2#1487 AS features#1492]\n                                 :           +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#1486, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#1487]\n                                 :              +- ExternalRDD [obj#1485]\n                                 +- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 53), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 53))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 53))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 53))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#1584]\n                                    +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3625/1299762647@45a3ca94, obj#1583: scala.collection.Seq\n                                       +- DeserializeToObject newInstance(class scala.Tuple2), obj#1582: scala.Tuple2\n                                          +- Project [_1#1498 AS id#1503, _2#1499 AS features#1504]\n                                             +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#1498, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#1499]\n                                                +- ExternalRDD [obj#1497]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iQor4uMpeA8"
      },
      "source": [
        "# Approach with Dask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaRd8TWMXyJt"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fVZ9cwjD79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5564e567-d1ae-46a3-f7b7-9281ff9a227e"
      },
      "source": [
        "!pip install \"dask[complete]\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: PyYaml; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: pandas>=0.23.0; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.0)\n",
            "Collecting fsspec>=0.6.0; extra == \"complete\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.19.5)\n",
            "Collecting distributed>=2.0; extra == \"complete\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/8b/0d704fdaa170a05797057c4676ceb9f53e139111b9b37f53e90a62c4c770/distributed-2021.7.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.0)\n",
            "Requirement already satisfied: bokeh>=1.0.0; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Collecting partd>=0.3.10; extra == \"complete\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"complete\"->dask[complete]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"complete\"->dask[complete]) (2.8.1)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (5.1.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (1.0.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (57.0.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (3.7.4.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (21.0)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0; extra == \"complete\"->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.4.7)\n",
            "\u001b[31mERROR: distributed 2021.7.0 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: distributed 2021.7.0 has requirement dask==2021.07.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fsspec, distributed, locket, partd\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed distributed-2021.7.0 fsspec-2021.7.0 locket-0.2.1 partd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m_LJJvhic3P"
      },
      "source": [
        "import joblib\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K67zWo9bwnSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb7ca25-1601-4a54-b8c0-6038e78a18ea"
      },
      "source": [
        "!python -m pip install dask distributed --upgrade"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dask\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/22/c99e0377c0b8d4679ae93d7d495349333c8b1455938c528eb9f66b850b04/dask-2021.7.0-py3-none-any.whl (977kB)\n",
            "\r\u001b[K     |▍                               | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 18.6MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 19.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 17.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 17.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 17.8MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 16.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 16.0MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 16.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 16.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 665kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 675kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 686kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 696kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 706kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 716kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 727kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 737kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 747kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 757kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 768kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 778kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 788kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 798kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 808kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 819kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 829kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 839kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 849kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 860kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 870kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 880kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 890kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 901kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 911kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 921kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 931kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 942kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 952kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 962kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 972kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 983kB 16.0MB/s \n",
            "\u001b[?25hRequirement already up-to-date: distributed in /usr/local/lib/python3.7/dist-packages (2021.7.0)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask) (2021.7.0)\n",
            "Requirement already satisfied, skipping upgrade: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed) (1.0.1)\n",
            "\u001b[31mERROR: distributed 2021.7.0 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dask\n",
            "  Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "Successfully installed dask-2021.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8lD8hN5jIut"
      },
      "source": [
        "from dask.distributed import Client\n",
        "client = Client(n_workers=4, threads_per_worker=4, processes=False, memory_limit='8GB')\n",
        "\n",
        "# If we doesn't convert userId to category then will met errors\n",
        "\n",
        "model_knn= NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20)\n",
        "movies_users= ratings.limit(1000000).toPandas().pivot(index='movieId', columns='userId',values='rating').fillna(0)\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf3dtGaRPRGb"
      },
      "source": [
        "import dask\n",
        "import dask.dataframe as dd\n",
        "ratings_dask_df = dd.read_csv('./drive/MyDrive/BigDataProject/ratings.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXVTkBORPuep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "65b1a585-d295-4608-f795-3cc1a9117ed1"
      },
      "source": [
        "ratings_dask_df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distributed.worker - WARNING - Compute Failed\n",
            "Function:  safe_head\n",
            "args:      ((<Serialize: subgraph_callable-17b9ef91-0ec5-45c3-a134-5d1202ec06f6>, <Serialize: [(<function read_block_from_file at 0x7f374eb3b5f0>, <OpenFile '/content/./drive/MyDrive/BigDataProject/ratings.csv'>, 0, 64000000, b'\\n'), None, True]>), 5)\n",
            "kwargs:    {}\n",
            "Exception: AttributeError(\"'tuple' object has no attribute 'head'\")\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c7b439276eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mratings_dask_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \"\"\"\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_head\u001b[0;34m(self, n, npartitions, compute, safe)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2702\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2022\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2025\u001b[0m             )\n\u001b[1;32m   2026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             return sync(\n\u001b[0;32m--> 860\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m             )\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhad_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1881\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36msafe_head\u001b[0;34m(df, n)\u001b[0m\n\u001b[1;32m   6705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6706\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6707\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6709\u001b[0m         msg = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dask/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huENAvcnpwJ9"
      },
      "source": [
        "with joblib.parallel_backend('dask'):\n",
        "    mat_movies_users=csr_matrix(movies_users.values)\n",
        "    model_knn.fit(mat_movies_users)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-g5SCgsj1tU"
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import process\n",
        "def recommender(movie_name, data, model, n_recommendations ):\n",
        "    df_movies = movies.toPandas()\n",
        "    model.fit(data)\n",
        "    idx=process.extractOne(movie_name, df_movies['title'])[2]\n",
        "    print('Movie Selected: ', df_movies['title'][idx], 'Index: ',idx)\n",
        "    print('Searching for recommendations.....')\n",
        "    distances, indices=model.kneighbors(data[idx], n_neighbors=n_recommendations)\n",
        "    for i in indices:\n",
        "        print(df_movies['title'][i].where(i!=idx))\n",
        "    \n",
        "recommender('Toy Story (1995)', mat_movies_users, model_knn,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWczmvNJ602"
      },
      "source": [
        "# SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwXu9_B9ryqm"
      },
      "source": [
        "## Basend on funk-svd is a Python 3 library implementing a fast version of the famous SVD algorithm popularized by Simon Funk during the Neflix Prize contest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbv_zIhWrsCL"
      },
      "source": [
        "!pip install git+https://github.com/gbolmier/funk-svd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ZdsYz2rICL"
      },
      "source": [
        "import pandas as pd\n",
        "from funk_svd import SVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpYRglFRhfGY"
      },
      "source": [
        "%%time\n",
        "with joblib.parallel_backend('dask'):\n",
        "  movies_df = movies.toPandas()\n",
        "  rating_df = ratings.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmCdvHCsreCQ"
      },
      "source": [
        "movies_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY4YuRVn0O-C"
      },
      "source": [
        "rating_df.columns = ['u_id', 'i_id', 'rating', 'timestamps']\n",
        "movies_df.columns = ['i_id', 'title', 'genres']\n",
        "rating_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV8IKSN_rfRJ"
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# movielens18.drop(columns = 'timestamp', inplace = True)\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "  train = rating_df.sample(frac=0.8)\n",
        "  val = rating_df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
        "  test = rating_df.drop(train.index.tolist()).drop(val.index.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5hDOidkz_z4"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwLqSUT5zFzK"
      },
      "source": [
        "lr, reg, factors = (0.01, 0.03, 90)\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "  svd = SVD(lr=lr, reg=reg, n_epochs=20, n_factors=factors,\n",
        "            min_rating=0.5, max_rating=5)\n",
        "  svd.fit(X=train, X_val=val)\n",
        "\n",
        "pred = svd.predict(test)\n",
        "mae = mean_absolute_error(test[\"rating\"], pred)\n",
        "rmse = np.sqrt(mean_squared_error(test[\"rating\"], pred))\n",
        "print(\"Test MAE:  {:.2f}\".format(mae))\n",
        "print(\"Test RMSE: {:.2f}\".format(rmse))\n",
        "print('{} factors, {} lr, {} reg'.format(factors, lr, reg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJkCYfVF5b_W"
      },
      "source": [
        "#User Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrbPvker4z69"
      },
      "source": [
        "n_m = len(rating_df.i_id.unique())\n",
        "\n",
        "#  Initialize my ratings\n",
        "my_ratings = np.zeros(n_m)\n",
        "\n",
        "\n",
        "my_ratings[4993] = 5\n",
        "my_ratings[1080] = 5\n",
        "my_ratings[260] = 5\n",
        "my_ratings[4896] = 5\n",
        "my_ratings[1196] = 5\n",
        "my_ratings[1210] = 5\n",
        "my_ratings[2628] = 5\n",
        "my_ratings[5378] = 5\n",
        "\n",
        "print('User ratings:')\n",
        "print('-----------------')\n",
        "\n",
        "for i, val in enumerate(my_ratings):\n",
        "    if val > 0:\n",
        "        print('Rated %d stars: %s' % (val, movies_df.loc[movies_df.i_id==i].title.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeOVTG-557mC"
      },
      "source": [
        "\n",
        "print(\"Adding your recommendations!\")\n",
        "items_id = [item[0] for item in np.argwhere(my_ratings>0)]\n",
        "ratings_list = my_ratings[np.where(my_ratings>0)]\n",
        "user_id = np.asarray([0] * len(ratings_list))\n",
        "\n",
        "user_ratings = pd.DataFrame(list(zip(user_id, items_id, ratings_list)), columns=['u_id', 'i_id', 'rating'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irkcdH8x6FRv"
      },
      "source": [
        "try:\n",
        "    rating_df = rating_df.drop(columns=['timestamps'])\n",
        "except:\n",
        "    pass\n",
        "data_with_user = rating_df.append(user_ratings, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "  train_user = data_with_user.sample(frac=0.8)\n",
        "  val_user = data_with_user.drop(train_user.index.tolist()).sample(frac=0.5, random_state=8)\n",
        "  test_user = data_with_user.drop(train_user.index.tolist()).drop(val_user.index.tolist())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYIKaEAqzMBE"
      },
      "source": [
        "from itertools import product\n",
        "\n",
        "\n",
        "def funk_svd_predict(userID, data_with_user, movies_df):\n",
        "    userID = [userID]\n",
        "\n",
        "    # all_users = data_with_user.u_id.unique()\n",
        "    all_movies = data_with_user.i_id.unique()\n",
        "    recommendations = pd.DataFrame(list(product(userID, all_movies)), columns=['u_id', 'i_id'])\n",
        "\n",
        "    #Getting predictions for the selected userID\n",
        "    pred_train = svd.predict(recommendations)\n",
        "    recommendations['prediction'] = pred_train\n",
        "    recommendations.head(10)\n",
        "\n",
        "    sorted_user_predictions = recommendations.sort_values(by='prediction', ascending=False)\n",
        "\n",
        "    user_ratings = data_with_user[data_with_user.u_id == userID[0]]\n",
        "    user_ratings.columns = ['u_id',\t'i_id', 'rating']\n",
        "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
        "    recommendations = movies_df[~movies_df['i_id'].isin(user_ratings['i_id'])].\\\n",
        "        merge(pd.DataFrame(sorted_user_predictions).reset_index(drop=True), how = 'inner', left_on = 'i_id', right_on = 'i_id').\\\n",
        "        sort_values(by='prediction', ascending = False)#.drop(['i_id'],axis=1)\n",
        "\n",
        "    rated_df = movies_df[movies_df['i_id'].isin(user_ratings['i_id'])].\\\n",
        "        merge(pd.DataFrame(data_with_user).reset_index(drop=True), how = 'inner', left_on = 'i_id', right_on = 'i_id')\n",
        "    rated_df = rated_df.loc[rated_df.u_id==userID[0]].sort_values(by='rating', ascending = False)\n",
        "    \n",
        "    return recommendations, rated_df\n",
        "recommendations, rated_df = funk_svd_predict(0, data_with_user, movies_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TdIy7c48hbU"
      },
      "source": [
        "rated_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKy2wIE2_Gkt"
      },
      "source": [
        "recommendations.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIE4njIX_OdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOI-qBp7_Uka"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}